{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBA DSA USP/ESALQ 2024.1 Time 2\n",
    "## Desafio House Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ser feito ainda:\n",
    "- Melhor imputação dos NaN\n",
    "- Verificar limpeza dos dados\n",
    "- Ver sobre feature engeneering\n",
    "- Seleção de variáveis?\n",
    "- Testes estatísticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza e ajuste dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura dos dados do arquivo para treino (\"train.csv\") e armazenando no objeto 'dados_brutos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de linhas e colunas\n",
      "(1460, 81)\n",
      "\n",
      "Tipos de objetos do DataFrame\n",
      "Id                 int64\n",
      "MSSubClass         int64\n",
      "MSZoning          object\n",
      "LotFrontage      float64\n",
      "LotArea            int64\n",
      "                  ...   \n",
      "MoSold             int64\n",
      "YrSold             int64\n",
      "SaleType          object\n",
      "SaleCondition     object\n",
      "SalePrice          int64\n",
      "Length: 81, dtype: object\n"
     ]
    }
   ],
   "source": [
    "dados_brutos = pd.read_csv(\"train.csv\")\n",
    "\n",
    "print(\"Quantidade de linhas e colunas\")\n",
    "print(dados_brutos.shape)\n",
    "\n",
    "print(\"\\nTipos de objetos do DataFrame\")\n",
    "print(dados_brutos.dtypes)\n",
    "\n",
    "#print(\"\\nInformações sobre o banco de dados (coluna, contador de nulos, e tipo de informação)\")\n",
    "#dados_brutos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O banco de dados possui uma série de colunas (variáveis) que possuem valores nulos, algumas em maior quantidade e outras em menor quantidade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de valores nulos por coluna:\n",
      "PoolQC          1453\n",
      "MiscFeature     1406\n",
      "Alley           1369\n",
      "Fence           1179\n",
      "FireplaceQu      690\n",
      "LotFrontage      259\n",
      "GarageYrBlt       81\n",
      "GarageCond        81\n",
      "GarageType        81\n",
      "GarageFinish      81\n",
      "GarageQual        81\n",
      "BsmtFinType2      38\n",
      "BsmtExposure      38\n",
      "BsmtQual          37\n",
      "BsmtCond          37\n",
      "BsmtFinType1      37\n",
      "MasVnrArea         8\n",
      "MasVnrType         8\n",
      "Electrical         1\n",
      "Id                 0\n",
      "dtype: int64\n",
      "Como o último valor já é zero, depois desse todos são zerados mesmo\n"
     ]
    }
   ],
   "source": [
    "nulos = dados_brutos.isnull().sum()\n",
    "nulos_ordenados = nulos.sort_values(ascending=False)\n",
    "\n",
    "print(\"Quantidade de valores nulos por coluna:\")\n",
    "print(nulos_ordenados.head(20))\n",
    "print(\"Como o último valor já é zero, depois desse todos são zerados mesmo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como são valores absolutos, é mais fácil excluir do banco de dados as variáveis que possuam valores nulos acima de um determinado percentual do total (eu usei 15% como delimitador), salvando no objeto 'dados_filtrados'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de linhas e colunas depois de ajustado\n",
      "(1460, 75)\n",
      "\n",
      "Tipos de objetos do DataFrame\n",
      "Id                int64\n",
      "MSSubClass        int64\n",
      "MSZoning         object\n",
      "LotArea           int64\n",
      "Street           object\n",
      "                  ...  \n",
      "MoSold            int64\n",
      "YrSold            int64\n",
      "SaleType         object\n",
      "SaleCondition    object\n",
      "SalePrice         int64\n",
      "Length: 75, dtype: object\n"
     ]
    }
   ],
   "source": [
    "nulos_percentuais = nulos/len(dados_brutos.index)\n",
    "var_excluir = dados_brutos.columns[nulos_percentuais > 0.15]\n",
    "dados_filtrados = dados_brutos.drop(var_excluir, axis = 1)\n",
    "\n",
    "print(\"Quantidade de linhas e colunas depois de ajustado\")\n",
    "print(dados_filtrados.shape)\n",
    "\n",
    "print(\"\\nTipos de objetos do DataFrame\")\n",
    "print(dados_filtrados.dtypes)\n",
    "\n",
    "#print(\"\\nInformações sobre o banco de dados (coluna, contador de nulos, e tipo de informação)\")\n",
    "#dados_filtrados.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso feito, existem variáveis que são 'object' (não-numérico, então qualitativas ou categóricas) e variáveis que são \"intXX\" (portanto, numéricas). Por questão de facilidade e considerando o tempo disponível, por enquanto vou desconsiderar as variáveis 'quali' e vou utilizar apenas as 'quanti'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_quali = dados_filtrados.columns[dados_filtrados.dtypes == \"object\"]\n",
    "variaveis_quanti = dados_filtrados.drop(colunas_quali, axis = 1)\n",
    "#print(\"AS VARIÁVEIS NUMÉRICAS ('QUANTI') ENTÃO SÃO 37:\")\n",
    "#print(variaveis_quanti.columns)\n",
    "#print(\"\\n\")\n",
    "\n",
    "colunas_quanti = dados_filtrados.columns[dados_filtrados.dtypes != \"object\"]\n",
    "variaveis_quali = dados_filtrados.drop(colunas_quanti, axis = 1)\n",
    "#print(\"AS VARIÁVEIS NÃO-NÚMERICAS ('QUALI') FICAM SENDO APENAS 38:\")\n",
    "#print(variaveis_quali.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Filtro das variáveis quali e quanti para evitar confusão. Contudo, ainda existem valores nulos no meio dos dados (foram eliminados só as variações com nulos >= 15% do total). Necessário realizar a imputação esses valores, pois nenhuma análise é feita com qualquer valor nulo: quebra o sistema.\n",
    "\n",
    " Link sobre o carregamento das bibliotecas para imputar dados: https://medium.com/@sanjushusanth/missing-value-imputation-techniques-in-python-62aeab65a6a6\n",
    "\n",
    " Por mera facilidade momentânea, serão utilizados os dados de média e mediana para as imputações, ou, ainda seguindo o que alguns consideram 'boas práticas', simplesmente registrando um '-1' no valor imputado. Fiz um banco de dados para cada tipo dessas imputações a fim de testar qual melhor se encaixa nessa simples imputação (sem cálculos próprios de imputação para esse fim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERIFICANDO VARIÁVEIS C/ IMPUTAÇÃO '-1' AINDA COM VALORES NULOS...\n",
      "Index([], dtype='object')\n",
      "\n",
      " VERIFICANDO VARIÁVEIS C/ IMPUTAÇÃO 'MÉDIA' AINDA COM VALORES NULOS...\n",
      "Index([], dtype='object')\n",
      "\n",
      " VERIFICANDO VARIÁVEIS C/ IMPUTAÇÃO 'MEDIANA' AINDA COM VALORES NULOS...\n",
      "Index([], dtype='object')\n",
      "\n",
      "TUDO CERTO!\n"
     ]
    }
   ],
   "source": [
    "variaveis_quanti_namum = variaveis_quanti.fillna(-1)\n",
    "variaveis_quanti_namediana = variaveis_quanti.fillna(variaveis_quanti.median())\n",
    "variaveis_quanti_namedia = variaveis_quanti.fillna(variaveis_quanti.mean())\n",
    "\n",
    "print(\"VERIFICANDO VARIÁVEIS C/ IMPUTAÇÃO '-1' AINDA COM VALORES NULOS...\")\n",
    "print(variaveis_quanti_namum.columns[variaveis_quanti_namum.isnull().sum() > 0])\n",
    "\n",
    "print(\"\\n VERIFICANDO VARIÁVEIS C/ IMPUTAÇÃO 'MÉDIA' AINDA COM VALORES NULOS...\")\n",
    "print(variaveis_quanti_namum.columns[variaveis_quanti_namedia.isnull().sum() > 0])\n",
    "\n",
    "print(\"\\n VERIFICANDO VARIÁVEIS C/ IMPUTAÇÃO 'MEDIANA' AINDA COM VALORES NULOS...\")\n",
    "print(variaveis_quanti_namum.columns[variaveis_quanti_namediana.isnull().sum() > 0])\n",
    "\n",
    "try:\n",
    "    variaveis_quanti_namum.columns[variaveis_quanti_namediana.isnull().sum() > 0] + variaveis_quanti_namum.columns[variaveis_quanti_namedia.isnull().sum() > 0]+ variaveis_quanti_namum.columns[variaveis_quanti_namum.isnull().sum() > 0]\n",
    "    print(\"\\nTUDO CERTO!\")\n",
    "except:\n",
    "    print(\"\\n!!! DEU ALGUM ERRO !!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição da variável dependente (y) e das variáveis independentes (x) de cada um dos bancos de dados anteriores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_namum = variaveis_quanti_namum.drop(\"SalePrice\", axis = 1)\n",
    "x_namedia = variaveis_quanti_namedia.drop(\"SalePrice\", axis = 1)\n",
    "x_namediana = variaveis_quanti_namediana.drop(\"SalePrice\", axis = 1)\n",
    "y = variaveis_quanti.SalePrice # como o 'y' é igual para todos (o preço de venda), então tanto faz a base de dados escolhida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação dos dados para treino e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação das bibliotecas adicionais necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação do banco de dados entre treino (0,80 ou 80%) e teste (0,20 ou 20%) - proporções arbitrárias, eu que defini assim. Pode-se testar com proporções diferentes. Usa-se o scikit-learn: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "Para garantir consistência entre os resultados, utilizado sempre _random_state = 1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação treino e teste dos dados imputados com -1\n",
    "treino_namum, teste_namum, treino_y_um, teste_y_um = train_test_split(x_namum, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "# Separação treino e teste dos dados imputados com a média\n",
    "treino_namedia, teste_namedia, treino_y_media, teste_y_media = train_test_split(x_namedia, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "# Separação treino e teste dos dados imputados com a mediana\n",
    "treino_namediana, teste_namediana, treino_y_mediana, teste_y_mediana = train_test_split(x_namediana, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelagem e posterior avaliação dos resultados\n",
    "Com os dados já limpos, já separados pelas imputações diferentes para verificação e com as bases para treino e teste, começa-se efetivamente a modelagem através de alguns algoritmos diferentes a fim de testar precisão dos resultados estimados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação das bibliotecas adicionais necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree # biblioteca para modelagem através de decision tree (árvore de decisão)\n",
    "from sklearn.neighbors import KNeighborsRegressor # biblioteca para modelagem através de KNN\n",
    "from sklearn.ensemble import GradientBoostingRegressor # biblioteca para modelagem com Gradient Boost\n",
    "from sklearn.linear_model import LinearRegression # biblioteca para modelagem através de regressão Linear Simples\n",
    "from sklearn.linear_model import LogisticRegression # biblioteca para modelagem com Logistic Regression\n",
    "from sklearn.linear_model import Ridge # biblioteca para modelagem com Ridge\n",
    "from sklearn import linear_model # biblioteca para modelagem com Bayesian Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Documentação\n",
    "Linear Regression (Regressão Linear)\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression\n",
    "\n",
    "Decision Tree (Árvore de Decisão)\n",
    "https://scikit-learn.org/stable/modules/tree.html#regression\n",
    "\n",
    "KNN - K Nearest Neighbors (Vizinhança Próxima)\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\n",
    "\n",
    "Gradient Boost Regressor\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor\n",
    "\n",
    "Logistic Regression (Modelo Logístico, 'Logit' ou Classificador de Máxima Entropia)\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\n",
    "\n",
    "Ridge\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge\n",
    "\n",
    "Bayesian Ridge Regression\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html#sklearn.linear_model.BayesianRidge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NaN imputado com -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Regressão Linear Simples (Linear Regression)\n",
    "namum_rl = LinearRegression().fit(treino_namum, treino_y_um)\n",
    "y_namum_rl = namum_rl.predict(teste_namum)\n",
    "\n",
    "# Árvore de Decisão (decision tree)\n",
    "namum_tree = tree.DecisionTreeRegressor(random_state = 1).fit(treino_namum, treino_y_um)\n",
    "y_namum_tree = namum_tree.predict(teste_namum)\n",
    "\n",
    "#(K Vizinhos Mais Próximos - KNN (K Nearest Neighbors))\n",
    "namum_knn = KNeighborsRegressor(n_neighbors = 2, weights = \"uniform\").fit(treino_namum, treino_y_um)\n",
    "y_namum_knn = namum_knn.predict(teste_namum)\n",
    "\n",
    "#Gradient Boost Regressor\n",
    "namum_gbr = GradientBoostingRegressor(random_state = 1).fit(treino_namum, treino_y_um)\n",
    "y_namum_gbr = namum_gbr.predict(teste_namum)\n",
    "\n",
    "#Logistic Regression\n",
    "namum_lor = LogisticRegression(random_state = 1, max_iter = 1000).fit(treino_namum, treino_y_um)\n",
    "y_namum_lor = namum_lor.predict(teste_namum)\n",
    "\n",
    "#Ridge\n",
    "namum_ridge = Ridge(alpha = 1.0).fit(treino_namum, treino_y_um)\n",
    "y_namum_ridge = namum_ridge.predict(teste_namum)\n",
    "\n",
    "#Bayesian Ridge Regression\n",
    "namum_brr = linear_model.BayesianRidge().fit(treino_namum, treino_y_um)\n",
    "y_namum_brr = namum_brr.predict(teste_namum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NaN imputado com Média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Regressão Linear Simples (Linear Regression)\n",
    "namedia_rl = LinearRegression().fit(treino_namedia, treino_y_media)\n",
    "y_namedia_rl = namedia_rl.predict(teste_namedia)\n",
    "\n",
    "# Árvore de Decisão (decision tree)\n",
    "namedia_tree = tree.DecisionTreeRegressor(random_state = 1).fit(treino_namedia, treino_y_media)\n",
    "y_namedia_tree = namedia_tree.predict(teste_namedia)\n",
    "\n",
    "#(K Vizinhos Mais Próximos - KNN (K Nearest Neighbors))\n",
    "namedia_knn = KNeighborsRegressor(n_neighbors = 2, weights = \"uniform\").fit(treino_namedia, treino_y_media)\n",
    "y_namedia_knn = namedia_knn.predict(teste_namedia)\n",
    "\n",
    "#Gradient Boost Regressor\n",
    "namedia_gbr = GradientBoostingRegressor(random_state = 1).fit(treino_namedia, treino_y_media)\n",
    "y_namedia_gbr = namedia_gbr.predict(teste_namedia)\n",
    "\n",
    "#Logistic Regression\n",
    "namedia_lor = LogisticRegression(random_state = 1, max_iter = 1000).fit(treino_namedia, treino_y_media)\n",
    "y_namedia_lor = namedia_lor.predict(teste_namedia)\n",
    "\n",
    "#Ridge\n",
    "namedia_ridge = Ridge(alpha = 1.0).fit(treino_namedia, treino_y_media)\n",
    "y_namedia_ridge = namedia_ridge.predict(teste_namedia)\n",
    "\n",
    "#Bayesian Ridge Regression\n",
    "namedia_brr = linear_model.BayesianRidge().fit(treino_namedia, treino_y_media)\n",
    "y_namedia_brr = namedia_brr.predict(teste_namedia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NaN imputado com Mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Regressão Linear Simples (Linear Regression)\n",
    "namediana_rl = LinearRegression().fit(treino_namediana, treino_y_mediana)\n",
    "y_namediana_rl = namediana_rl.predict(teste_namediana)\n",
    "\n",
    "# Árvore de Decisão (decision tree)\n",
    "namediana_tree = tree.DecisionTreeRegressor(random_state = 1).fit(treino_namediana, treino_y_mediana)\n",
    "y_namediana_tree = namediana_tree.predict(teste_namediana)\n",
    "\n",
    "#(K Vizinhos Mais Próximos - KNN (K Nearest Neighbors))\n",
    "namediana_knn = KNeighborsRegressor(n_neighbors = 2, weights = \"uniform\").fit(treino_namediana, treino_y_mediana)\n",
    "y_namediana_knn = namediana_knn.predict(teste_namediana)\n",
    "\n",
    "#Gradient Boost Regressor\n",
    "namediana_gbr = GradientBoostingRegressor(random_state = 1).fit(treino_namediana, treino_y_mediana)\n",
    "y_namediana_gbr = namediana_gbr.predict(teste_namediana)\n",
    "\n",
    "#Logistic Regression\n",
    "namediana_lor = LogisticRegression(random_state = 1, max_iter = 1000).fit(treino_namediana, treino_y_mediana)\n",
    "y_namediana_lor = namediana_lor.predict(teste_namediana)\n",
    "\n",
    "#Ridge\n",
    "namediana_ridge = Ridge(alpha = 1.0).fit(treino_namediana, treino_y_mediana)\n",
    "y_namediana_ridge = namediana_ridge.predict(teste_namediana)\n",
    "\n",
    "#Bayesian Ridge Regression\n",
    "namediana_brr = linear_model.BayesianRidge().fit(treino_namediana, treino_y_mediana)\n",
    "y_namediana_brr = namediana_brr.predict(teste_namediana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação dos resultados realizada através de RMSE (root mean squared error), no caso deste desafio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação das bibliotecas adicionais necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análises (pela imputação)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NaN por -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "35621.27326115689\n",
      "\n",
      "Decision Tree\n",
      "35116.94890306209\n",
      "\n",
      "KNN\n",
      "53538.68340927549\n",
      "\n",
      "GBR\n",
      "22404.11312398332\n",
      "\n",
      "Logistic Regression\n",
      "56992.054928675374\n",
      "\n",
      "Ridge\n",
      "35608.081379361436\n",
      "\n",
      "Bayesian Ridge\n",
      "40229.11392691891\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression\")\n",
    "print(root_mean_squared_error(teste_y_um, y_namum_rl))\n",
    "print(\"\\nDecision Tree\")\n",
    "print(root_mean_squared_error(teste_y_um, y_namum_tree))\n",
    "print(\"\\nKNN\")\n",
    "print(root_mean_squared_error(teste_y_um, y_namum_knn))\n",
    "print(\"\\nGBR\")\n",
    "print(root_mean_squared_error(teste_y_um, y_namum_gbr))\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(root_mean_squared_error(teste_y_um, y_namum_lor))\n",
    "print(\"\\nRidge\")\n",
    "print(root_mean_squared_error(teste_y_um, y_namum_ridge))\n",
    "print(\"\\nBayesian Ridge\")\n",
    "print(root_mean_squared_error(teste_y_um, y_namum_brr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NaN por Média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "36078.05339518298\n",
      "\n",
      "Decision Tree\n",
      "47410.39995583883\n",
      "\n",
      "KNN\n",
      "53401.849345830655\n",
      "\n",
      "GBR\n",
      "23146.583584564967\n",
      "\n",
      "Logistic Regression\n",
      "53848.77888867462\n",
      "\n",
      "Ridge\n",
      "36065.19504911939\n",
      "\n",
      "Bayesian Ridge\n",
      "40239.30702099713\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression\")\n",
    "print(root_mean_squared_error(teste_y_media, y_namedia_rl))\n",
    "print(\"\\nDecision Tree\")\n",
    "print(root_mean_squared_error(teste_y_media, y_namedia_tree))\n",
    "print(\"\\nKNN\")\n",
    "print(root_mean_squared_error(teste_y_media, y_namedia_knn))\n",
    "print(\"\\nGBR\")\n",
    "print(root_mean_squared_error(teste_y_media, y_namedia_gbr))\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(root_mean_squared_error(teste_y_media, y_namedia_lor))\n",
    "print(\"\\nRidge\")\n",
    "print(root_mean_squared_error(teste_y_media, y_namedia_ridge))\n",
    "print(\"\\nBayesian Ridge\")\n",
    "print(root_mean_squared_error(teste_y_media, y_namedia_brr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NaN por Mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "36055.310690629514\n",
      "\n",
      "Decision Tree\n",
      "34013.71426658524\n",
      "\n",
      "KNN\n",
      "53488.18385333421\n",
      "\n",
      "GBR\n",
      "23125.9818814507\n",
      "\n",
      "Logistic Regression\n",
      "51854.51240034369\n",
      "\n",
      "Ridge\n",
      "36042.55239994742\n",
      "\n",
      "Bayesian Ridge\n",
      "40228.513586626104\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression\")\n",
    "print(root_mean_squared_error(teste_y_mediana, y_namediana_rl))\n",
    "print(\"\\nDecision Tree\")\n",
    "print(root_mean_squared_error(teste_y_mediana, y_namediana_tree))\n",
    "print(\"\\nKNN\")\n",
    "print(root_mean_squared_error(teste_y_mediana, y_namediana_knn))\n",
    "print(\"\\nGBR\")\n",
    "print(root_mean_squared_error(teste_y_mediana, y_namediana_gbr))\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(root_mean_squared_error(teste_y_mediana, y_namediana_lor))\n",
    "print(\"\\nRidge\")\n",
    "print(root_mean_squared_error(teste_y_mediana, y_namediana_ridge))\n",
    "print(\"\\nBayesian Ridge\")\n",
    "print(root_mean_squared_error(teste_y_mediana, y_namediana_brr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O modelo para publicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBR com mediana (23125.98188)\n",
    "\n",
    "# Carregamento do dataset\n",
    "teste = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Filtro das colunas utilizadas e imputação dos NaN\n",
    "colunas_quali_teste = teste.columns[teste.dtypes == \"object\"]\n",
    "variaveis_quanti_teste = teste.drop(colunas_quali_teste, axis = 1)\n",
    "variaveis_quanti_teste = variaveis_quanti_teste.drop(\"LotFrontage\", axis = 1)\n",
    "variaveis_quanti_teste = variaveis_quanti_teste.fillna(variaveis_quanti_teste.median())\n",
    "\n",
    "# Gerando as previsões\n",
    "y_gbr = namediana_gbr.predict(variaveis_quanti_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerar arquivo de submissão\n",
    "Pontuação 0.14569 (quanto menor, melhor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste[\"SalePrice\"] = y_gbr\n",
    "resultado = teste[[\"Id\", \"SalePrice\"]]\n",
    "resultado.to_csv(\"resultado.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

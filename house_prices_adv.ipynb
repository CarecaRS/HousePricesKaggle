{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBA DSA USP/ESALQ 2024.1 Time 2\n",
    "## Desafio House Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A fazer:\n",
    "- Limpeza geral\n",
    "- Análise das variáveis (categóricas/numéricas(discretas-contínuas)/trocadas)\n",
    "- Outliers?\n",
    "- Normalização dos dados de regressão não-gaussianos\n",
    "- Análise de correlação\n",
    "- Escolha das variáveis categóricas/numéricas\n",
    "- Imputação dos NaN\n",
    "- Multicolineariedade?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura dos dados amplos (arquivos de treino/teste) para unificação e tratamento por completo antes da modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de linhas e colunas\n",
      "(2919, 82)\n"
     ]
    }
   ],
   "source": [
    "treino = pd.read_csv(\"train.csv\")\n",
    "teste = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Ajuste das dimensões - inclusão da coluna SalePrice no dataset de teste\n",
    "teste[\"SalePrice\"] = 0\n",
    "\n",
    "# Inclusão de informação sobre dataset de origem\n",
    "teste[\"Origem\"] = \"Teste\"\n",
    "treino[\"Origem\"] = \"Treino\"\n",
    "\n",
    "dados_brutos = pd.concat([treino, teste])\n",
    "\n",
    "print(\"Quantidade de linhas e colunas\")\n",
    "print(dados_brutos.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise das variáveis categóricas/de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O banco de dados possui uma série de colunas (variáveis) que possuem valores nulos, algumas em maior quantidade e outras em menor quantidade, que serão revisitados depois:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação das variáveis entre categóricas e numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "coluna_origem = dados_brutos[\"Origem\"]\n",
    "\n",
    "colunas_quali = dados_brutos.columns[dados_brutos.dtypes == \"object\"]\n",
    "variaveis_quanti = dados_brutos.drop(colunas_quali, axis = 1)\n",
    "\n",
    "colunas_quanti = dados_brutos.columns[dados_brutos.dtypes != \"object\"]\n",
    "variaveis_quali = dados_brutos.drop(colunas_quanti, axis = 1)\n",
    "\n",
    "\"\"\"\n",
    "#print(\"AS VARIÁVEIS NUMÉRICAS ('QUANTI') ENTÃO SÃO \" + str(len(variaveis_quanti.columns)) + \":\")\n",
    "#print(variaveis_quanti.columns)\n",
    "#print(\"\\n\")\n",
    "\n",
    "#print(\"AS VARIÁVEIS NÃO-NÚMERICAS ('QUALI') FICAM SENDO APENAS \" + str(len(variaveis_quali.columns)) + \":\")\n",
    "#print(variaveis_quali.columns)\n",
    "#print(\"\\n\")\n",
    "\n",
    "\"\"\"\n",
    "#print(\"REINSERÇÃO DA COLUNA 'ORIGEM' PARA CONTROLE NAS VARIÁVEIS QUANTI:\")\n",
    "variaveis_quanti[\"Origem\"] = coluna_origem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variáveis de Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas variáveis tem valores nulos, que serão imputados com classificações apropriadas. O processo de decisão sobre a imputação é tratado caso a caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"Percentual de valores nulos por cada variável:\")\\nprint(nulos_ordenados.head(25))\\nprint(\"\\nComo os últimos valores já são zero, depois desses todos são zerados mesmo. Ou seja, não existem valores nulos nas outras variáveis\")\\n'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulos = variaveis_quali.isnull().sum()\n",
    "nulos_ordenados = (nulos.sort_values(ascending=False)/len(variaveis_quali))*100\n",
    "\n",
    "\"\"\"\n",
    "print(\"Percentual de valores nulos por cada variável:\")\n",
    "print(nulos_ordenados.head(25))\n",
    "print(\"\\nComo os últimos valores já são zero, depois desses todos são zerados mesmo. Ou seja, não existem valores nulos nas outras variáveis\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificação das variáveis com maior falta de dados. Como tratam-se de variáveis de classificação, muitas vezes a imputação é simples e válida de ser feita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print(\"Variáveis com % significativo de falta de dados (acima de 20%):\")\n",
    "print(nulos_ordenados.head(5))\n",
    "print(\"\\nAs demais variáveis terão todos seus valores NaN imputados ou as observações NaN serão desconsideradas.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descrição das variáveis com maior falta de dados: \n",
    "- PoolQC: valores NaN indicam inexistência de piscina (imputar 'None' então)\n",
    "- MiscFeature: miscelânea, NaN indica inexistência desse tipo de feature (imputar 'None')\n",
    "- Alley: tipo de viela/ruazinha para acesso à casa. Se a casa tem saída para a rua principal, a característica não tem nem como existir (imputar 'None')\n",
    "- Fence: qualidade da cerca da casa, se a casa não possui cerca por obviedade essa informação é NaN (imputar 'None')\n",
    "- FireplaceQu: indica existência de lareira na casa (imputar 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputar_none = [\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\"]\n",
    "variaveis_quali[imputar_none] = variaveis_quali[imputar_none].fillna(\"None\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demais variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "nulos = variaveis_quali.isnull().sum()\n",
    "nulos_ordenados = nulos.sort_values(ascending=False)\n",
    "\n",
    "temp = pd.DataFrame(nulos_ordenados)\n",
    "mask = temp[0].isin([0])\n",
    "print(temp[~mask].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputação de 'None' diretamente:\n",
    "- \"Garage\"XYZ: as variáveis \"Garage\"XYZ classificam o estado de conservação, acabamento e localização da garagem, se existente. NaN indica inexistência de garagem (imputa 'None').\n",
    "- \"Bsmt\"XYZ: as variáveis \"Bsmt\"XYZ classificam o nível de qualidade, exposição e acabamentos do porão, se existente. NaN indica inexistência de porão (imputa 'None').\n",
    "- Exterior1st: Exterior covering on house. Deduzo que NaN indique inexistência, imputa 'None'.\n",
    "- Exterior2nd: Exterior covering on house (if more than one material) (deve ter correlação direta com o acima).\n",
    "- MasVnrType: Masonry veneer type. Descrição contempla opção de 'None', assume-se que informação inexistente corresponda a 'None'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputar_none2 = ['GarageCond', 'GarageQual', 'GarageFinish', 'GarageType', 'BsmtCond', 'BsmtExposure', 'BsmtQual', 'BsmtFinType2', 'BsmtFinType1','Exterior1st', 'Exterior2nd', 'MasVnrType']\n",
    "variaveis_quali[imputar_none2] = variaveis_quali[imputar_none2].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputação arbitrada para a classificação:\n",
    "- Functional: Home functionality (Assume typical unless deductions are warranted). NaN imputado \"Typ\".\n",
    "- SaleType: tipo de venda, imputado moda de \"OverallCond\" (banco de dados original).\n",
    "- Utilities: tipos de serviços básicos disponíveis (água, luz, gás, etc.). Imputada moda da vizinhança.\n",
    "- KitchenQual: qualidade da cozinha. Imputada moda da vizinhança.\n",
    "- Electrical: Electrical system. Imputada moda da vizinhança.\n",
    "- MSZoning: Identifies the general zoning classification of the sale. Como se trata de zoneamento, assume-se que em um mesmo bairro o zoneamento seja o mesmo(sem NaN na descrição)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variaveis imputadas com moda da região (vizinhança)\n",
    "\n",
    "variaveis_quali[\"Functional\"] = variaveis_quali[\"Functional\"].fillna(\"Typ\")\n",
    "variaveis_quali[\"Utilities\"] = variaveis_quali[\"Utilities\"].fillna(\"AllPub\")\n",
    "variaveis_quali[\"SaleType\"] = variaveis_quali[\"SaleType\"].fillna(\"WD\")\n",
    "variaveis_quali[\"MSZoning\"].loc[1444] = variaveis_quali[\"MSZoning\"].loc[1444].fillna(\"RL\") # específico para essa observação o bairro é diferente, com outra moda\n",
    "variaveis_quali[\"MSZoning\"] = variaveis_quali[\"MSZoning\"].fillna(\"RM\")\n",
    "\n",
    "\n",
    "# Processo da imputação (\"KitchenQual\", nessa explicação)\n",
    "# Primeiro vê qual observação é NaN, extraindo a informação sobre vizinhança\n",
    "kitchen_neigh = variaveis_quali[variaveis_quali[\"KitchenQual\"].isnull()][[\"Neighborhood\"]]\n",
    "# Com a informação sobre a vizinhança, verifica a moda da vizinhança para a variável com NaN\n",
    "kitchen_qual = variaveis_quali[variaveis_quali[\"Neighborhood\"] == kitchen_neigh.iloc[0,0]][[\"KitchenQual\"]].mode()\n",
    "# Por último, imputa a moda da vizinhança para a informação faltante\n",
    "variaveis_quali[\"KitchenQual\"] = variaveis_quali[\"KitchenQual\"].fillna(kitchen_qual.iloc[0,0])\n",
    "\n",
    "\n",
    "# Repete o processo acima, para a variável \"Electrical\"\n",
    "elec_neigh = variaveis_quali[variaveis_quali[\"Electrical\"].isnull()][[\"Neighborhood\"]]\n",
    "elec_qual = variaveis_quali[variaveis_quali[\"Neighborhood\"] == elec_neigh.iloc[0,0]][[\"Electrical\"]].mode()\n",
    "variaveis_quali[\"Electrical\"] = variaveis_quali[\"Electrical\"].fillna(elec_qual.iloc[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variáveis Numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentual de valores nulos por cada variável:\n",
      "LotFrontage     16.649538\n",
      "GarageYrBlt      5.447071\n",
      "MasVnrArea       0.787941\n",
      "BsmtHalfBath     0.068517\n",
      "BsmtFullBath     0.068517\n",
      "BsmtFinSF2       0.034258\n",
      "GarageCars       0.034258\n",
      "GarageArea       0.034258\n",
      "TotalBsmtSF      0.034258\n",
      "BsmtUnfSF        0.034258\n",
      "BsmtFinSF1       0.034258\n",
      "Fireplaces       0.000000\n",
      "dtype: float64\n",
      "\n",
      "Como os últimos valores já são zero, depois desses todos são zerados mesmo. Ou seja, não existem valores nulos nas outras variáveis\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nulos_quanti = variaveis_quanti.isnull().sum()\n",
    "nulos_ordenados_quanti = (nulos_quanti.sort_values(ascending=False)/len(variaveis_quanti))*100\n",
    "\n",
    "\n",
    "print(\"Percentual de valores nulos por cada variável:\")\n",
    "print(nulos_ordenados_quanti.head(12))\n",
    "print(\"\\nComo os últimos valores já são zero, depois desses todos são zerados mesmo. Ou seja, não existem valores nulos nas outras variáveis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As variáveis com valores nulos:\n",
    "\n",
    "- LotFrontage - Linear feet of street connected to property\n",
    "- GarageYrBlt - Ano em que a garagem foi construída. Se existe um NaN, assume-se que não tenha garagem, atribuindo-se 'None'. Transformar essa variável para classificação, uma vez que o ano de construção não é valor métrico. \n",
    "- MasVnrArea - Masonry veneer area in square feet. Deve ter relação direta com a MasVnrType - se esta é inexistente, então a área é 0 mesmo.\n",
    "- BsmtHalfBath - 'meio' banheiro no porão, se inexistente imputa 0. Classificação?\n",
    "- BsmtFullBath - banheiro no porão, se inexistente imputa 0. Classificação?\n",
    "- BsmtFinSF2 - área do banheiro no porão, se inexistente imputa 0.\n",
    "- GarageCars - tamanho da garagem em questão de capacidade de números de carros, se garagem inexistente então 0.\n",
    "- GarageArea - tamanho da garagem, se garagem inexistente então 0.\n",
    "- TotalBsmtSF - tamanho total do porão, se porão inexistente então 0.\n",
    "- BsmtUnfSF - área inacabada do porão, se porão inexistente então 0.\n",
    "- BsmtFinSF1 - área acabada do porão, se porão inexistente então 0.\n",
    "\n",
    "\n",
    "Com o ensejo da variável GarageYrBlt, transformar as variáveis de 'ano' em classificação. Algumas variáveis de ano (como ano de construção, reforma ou venda) serão utilizadas apenas para engenharia de features, neste caso então não interfere se o ano enquandra-se como variável métrica ou de classificação.\n",
    "\n",
    "Somar áreas de banheiro?\n",
    "Somar áreas totais?\n",
    "Somar quantidade total de banheiros?\n",
    "\n",
    "As variáveis \"xyzBath\" são de classificação?\n",
    "\n",
    "Como usa as variáveis de classificação e numéricas juntas? Passa as de classificação tudo para dummies e faz regressão normal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O TRABALHO INICIAL É DAQUI PARA BAIXO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Filtro das variáveis quali e quanti para evitar confusão. Contudo, ainda existem valores nulos no meio dos dados (foram eliminados só as variações com nulos >= 15% do total). Necessário realizar a imputação esses valores, pois nenhuma análise é feita com qualquer valor nulo: quebra o sistema.\n",
    "\n",
    " Link sobre o carregamento das bibliotecas para imputar dados: https://medium.com/@sanjushusanth/missing-value-imputation-techniques-in-python-62aeab65a6a6\n",
    "\n",
    " Por mera facilidade momentânea, serão utilizados os dados de média e mediana para as imputações, ou, ainda seguindo o que alguns consideram 'boas práticas', simplesmente registrando um '-1' no valor imputado. Fiz um banco de dados para cada tipo dessas imputações a fim de testar qual melhor se encaixa nessa simples imputação (sem cálculos próprios de imputação para esse fim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERIFICANDO VARIÁVEIS C/ IMPUTAÇÃO '-1' AINDA COM VALORES NULOS...\n",
      "Index([], dtype='object')\n",
      "\n",
      " VERIFICANDO VARIÁVEIS C/ IMPUTAÇÃO 'MÉDIA' AINDA COM VALORES NULOS...\n",
      "Index([], dtype='object')\n",
      "\n",
      " VERIFICANDO VARIÁVEIS C/ IMPUTAÇÃO 'MEDIANA' AINDA COM VALORES NULOS...\n",
      "Index([], dtype='object')\n",
      "\n",
      "TUDO CERTO!\n"
     ]
    }
   ],
   "source": [
    "variaveis_quanti_namum = variaveis_quanti.fillna(-1)\n",
    "variaveis_quanti_namediana = variaveis_quanti.fillna(variaveis_quanti.median())\n",
    "variaveis_quanti_namedia = variaveis_quanti.fillna(variaveis_quanti.mean())\n",
    "\n",
    "print(\"VERIFICANDO VARIÁVEIS C/ IMPUTAÇÃO '-1' AINDA COM VALORES NULOS...\")\n",
    "print(variaveis_quanti_namum.columns[variaveis_quanti_namum.isnull().sum() > 0])\n",
    "\n",
    "print(\"\\n VERIFICANDO VARIÁVEIS C/ IMPUTAÇÃO 'MÉDIA' AINDA COM VALORES NULOS...\")\n",
    "print(variaveis_quanti_namum.columns[variaveis_quanti_namedia.isnull().sum() > 0])\n",
    "\n",
    "print(\"\\n VERIFICANDO VARIÁVEIS C/ IMPUTAÇÃO 'MEDIANA' AINDA COM VALORES NULOS...\")\n",
    "print(variaveis_quanti_namum.columns[variaveis_quanti_namediana.isnull().sum() > 0])\n",
    "\n",
    "try:\n",
    "    variaveis_quanti_namum.columns[variaveis_quanti_namediana.isnull().sum() > 0] + variaveis_quanti_namum.columns[variaveis_quanti_namedia.isnull().sum() > 0]+ variaveis_quanti_namum.columns[variaveis_quanti_namum.isnull().sum() > 0]\n",
    "    print(\"\\nTUDO CERTO!\")\n",
    "except:\n",
    "    print(\"\\n!!! DEU ALGUM ERRO !!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição da variável dependente (y) e das variáveis independentes (x) de cada um dos bancos de dados anteriores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_namum = variaveis_quanti_namum.drop(\"SalePrice\", axis = 1)\n",
    "x_namedia = variaveis_quanti_namedia.drop(\"SalePrice\", axis = 1)\n",
    "x_namediana = variaveis_quanti_namediana.drop(\"SalePrice\", axis = 1)\n",
    "y = variaveis_quanti.SalePrice # como o 'y' é igual para todos (o preço de venda), então tanto faz a base de dados escolhida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação dos dados para treino e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação das bibliotecas adicionais necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação do banco de dados entre treino (0,80 ou 80%) e teste (0,20 ou 20%) - proporções arbitrárias, eu que defini assim. Pode-se testar com proporções diferentes. Usa-se o scikit-learn: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "Para garantir consistência entre os resultados, utilizado sempre _random_state = 1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação treino e teste dos dados imputados com -1\n",
    "treino_namum, teste_namum, treino_y_um, teste_y_um = train_test_split(x_namum, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "# Separação treino e teste dos dados imputados com a média\n",
    "treino_namedia, teste_namedia, treino_y_media, teste_y_media = train_test_split(x_namedia, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "# Separação treino e teste dos dados imputados com a mediana\n",
    "treino_namediana, teste_namediana, treino_y_mediana, teste_y_mediana = train_test_split(x_namediana, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelagem e posterior avaliação dos resultados\n",
    "Com os dados já limpos, já separados pelas imputações diferentes para verificação e com as bases para treino e teste, começa-se efetivamente a modelagem através de alguns algoritmos diferentes a fim de testar precisão dos resultados estimados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação das bibliotecas adicionais necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree # biblioteca para modelagem através de decision tree (árvore de decisão)\n",
    "from sklearn.neighbors import KNeighborsRegressor # biblioteca para modelagem através de KNN\n",
    "from sklearn.ensemble import GradientBoostingRegressor # biblioteca para modelagem com Gradient Boost\n",
    "from sklearn.linear_model import LinearRegression # biblioteca para modelagem através de regressão Linear Simples\n",
    "from sklearn.linear_model import LogisticRegression # biblioteca para modelagem com Logistic Regression\n",
    "from sklearn.linear_model import Ridge # biblioteca para modelagem com Ridge\n",
    "from sklearn import linear_model # biblioteca para modelagem com Bayesian Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Documentação\n",
    "Linear Regression (Regressão Linear)\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression\n",
    "\n",
    "Decision Tree (Árvore de Decisão)\n",
    "https://scikit-learn.org/stable/modules/tree.html#regression\n",
    "\n",
    "KNN - K Nearest Neighbors (Vizinhança Próxima)\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\n",
    "\n",
    "Gradient Boost Regressor\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor\n",
    "\n",
    "Logistic Regression (Modelo Logístico, 'Logit' ou Classificador de Máxima Entropia)\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\n",
    "\n",
    "Ridge\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge\n",
    "\n",
    "Bayesian Ridge Regression\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html#sklearn.linear_model.BayesianRidge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NaN imputado com -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Regressão Linear Simples (Linear Regression)\n",
    "namum_rl = LinearRegression().fit(treino_namum, treino_y_um)\n",
    "y_namum_rl = namum_rl.predict(teste_namum)\n",
    "\n",
    "# Árvore de Decisão (decision tree)\n",
    "namum_tree = tree.DecisionTreeRegressor(random_state = 1).fit(treino_namum, treino_y_um)\n",
    "y_namum_tree = namum_tree.predict(teste_namum)\n",
    "\n",
    "#(K Vizinhos Mais Próximos - KNN (K Nearest Neighbors))\n",
    "namum_knn = KNeighborsRegressor(n_neighbors = 2, weights = \"uniform\").fit(treino_namum, treino_y_um)\n",
    "y_namum_knn = namum_knn.predict(teste_namum)\n",
    "\n",
    "#Gradient Boost Regressor\n",
    "namum_gbr = GradientBoostingRegressor(random_state = 1).fit(treino_namum, treino_y_um)\n",
    "y_namum_gbr = namum_gbr.predict(teste_namum)\n",
    "\n",
    "#Logistic Regression\n",
    "namum_lor = LogisticRegression(random_state = 1, max_iter = 1000).fit(treino_namum, treino_y_um)\n",
    "y_namum_lor = namum_lor.predict(teste_namum)\n",
    "\n",
    "#Ridge\n",
    "namum_ridge = Ridge(alpha = 1.0).fit(treino_namum, treino_y_um)\n",
    "y_namum_ridge = namum_ridge.predict(teste_namum)\n",
    "\n",
    "#Bayesian Ridge Regression\n",
    "namum_brr = linear_model.BayesianRidge().fit(treino_namum, treino_y_um)\n",
    "y_namum_brr = namum_brr.predict(teste_namum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NaN imputado com Média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Regressão Linear Simples (Linear Regression)\n",
    "namedia_rl = LinearRegression().fit(treino_namedia, treino_y_media)\n",
    "y_namedia_rl = namedia_rl.predict(teste_namedia)\n",
    "\n",
    "# Árvore de Decisão (decision tree)\n",
    "namedia_tree = tree.DecisionTreeRegressor(random_state = 1).fit(treino_namedia, treino_y_media)\n",
    "y_namedia_tree = namedia_tree.predict(teste_namedia)\n",
    "\n",
    "#(K Vizinhos Mais Próximos - KNN (K Nearest Neighbors))\n",
    "namedia_knn = KNeighborsRegressor(n_neighbors = 2, weights = \"uniform\").fit(treino_namedia, treino_y_media)\n",
    "y_namedia_knn = namedia_knn.predict(teste_namedia)\n",
    "\n",
    "#Gradient Boost Regressor\n",
    "namedia_gbr = GradientBoostingRegressor(random_state = 1).fit(treino_namedia, treino_y_media)\n",
    "y_namedia_gbr = namedia_gbr.predict(teste_namedia)\n",
    "\n",
    "#Logistic Regression\n",
    "namedia_lor = LogisticRegression(random_state = 1, max_iter = 1000).fit(treino_namedia, treino_y_media)\n",
    "y_namedia_lor = namedia_lor.predict(teste_namedia)\n",
    "\n",
    "#Ridge\n",
    "namedia_ridge = Ridge(alpha = 1.0).fit(treino_namedia, treino_y_media)\n",
    "y_namedia_ridge = namedia_ridge.predict(teste_namedia)\n",
    "\n",
    "#Bayesian Ridge Regression\n",
    "namedia_brr = linear_model.BayesianRidge().fit(treino_namedia, treino_y_media)\n",
    "y_namedia_brr = namedia_brr.predict(teste_namedia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NaN imputado com Mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Regressão Linear Simples (Linear Regression)\n",
    "namediana_rl = LinearRegression().fit(treino_namediana, treino_y_mediana)\n",
    "y_namediana_rl = namediana_rl.predict(teste_namediana)\n",
    "\n",
    "# Árvore de Decisão (decision tree)\n",
    "namediana_tree = tree.DecisionTreeRegressor(random_state = 1).fit(treino_namediana, treino_y_mediana)\n",
    "y_namediana_tree = namediana_tree.predict(teste_namediana)\n",
    "\n",
    "#(K Vizinhos Mais Próximos - KNN (K Nearest Neighbors))\n",
    "namediana_knn = KNeighborsRegressor(n_neighbors = 2, weights = \"uniform\").fit(treino_namediana, treino_y_mediana)\n",
    "y_namediana_knn = namediana_knn.predict(teste_namediana)\n",
    "\n",
    "#Gradient Boost Regressor\n",
    "namediana_gbr = GradientBoostingRegressor(random_state = 1).fit(treino_namediana, treino_y_mediana)\n",
    "y_namediana_gbr = namediana_gbr.predict(teste_namediana)\n",
    "\n",
    "#Logistic Regression\n",
    "namediana_lor = LogisticRegression(random_state = 1, max_iter = 1000).fit(treino_namediana, treino_y_mediana)\n",
    "y_namediana_lor = namediana_lor.predict(teste_namediana)\n",
    "\n",
    "#Ridge\n",
    "namediana_ridge = Ridge(alpha = 1.0).fit(treino_namediana, treino_y_mediana)\n",
    "y_namediana_ridge = namediana_ridge.predict(teste_namediana)\n",
    "\n",
    "#Bayesian Ridge Regression\n",
    "namediana_brr = linear_model.BayesianRidge().fit(treino_namediana, treino_y_mediana)\n",
    "y_namediana_brr = namediana_brr.predict(teste_namediana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação dos resultados realizada através de RMSE (root mean squared error), no caso deste desafio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação das bibliotecas adicionais necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análises (pela imputação)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NaN por -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "35621.27326115689\n",
      "\n",
      "Decision Tree\n",
      "35116.94890306209\n",
      "\n",
      "KNN\n",
      "53538.68340927549\n",
      "\n",
      "GBR\n",
      "22404.11312398332\n",
      "\n",
      "Logistic Regression\n",
      "56992.054928675374\n",
      "\n",
      "Ridge\n",
      "35608.081379361436\n",
      "\n",
      "Bayesian Ridge\n",
      "40229.11392691891\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression\")\n",
    "print(root_mean_squared_error(teste_y_um, y_namum_rl))\n",
    "print(\"\\nDecision Tree\")\n",
    "print(root_mean_squared_error(teste_y_um, y_namum_tree))\n",
    "print(\"\\nKNN\")\n",
    "print(root_mean_squared_error(teste_y_um, y_namum_knn))\n",
    "print(\"\\nGBR\")\n",
    "print(root_mean_squared_error(teste_y_um, y_namum_gbr))\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(root_mean_squared_error(teste_y_um, y_namum_lor))\n",
    "print(\"\\nRidge\")\n",
    "print(root_mean_squared_error(teste_y_um, y_namum_ridge))\n",
    "print(\"\\nBayesian Ridge\")\n",
    "print(root_mean_squared_error(teste_y_um, y_namum_brr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NaN por Média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "36078.05339518298\n",
      "\n",
      "Decision Tree\n",
      "47410.39995583883\n",
      "\n",
      "KNN\n",
      "53401.849345830655\n",
      "\n",
      "GBR\n",
      "23146.583584564967\n",
      "\n",
      "Logistic Regression\n",
      "53848.77888867462\n",
      "\n",
      "Ridge\n",
      "36065.19504911939\n",
      "\n",
      "Bayesian Ridge\n",
      "40239.30702099713\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression\")\n",
    "print(root_mean_squared_error(teste_y_media, y_namedia_rl))\n",
    "print(\"\\nDecision Tree\")\n",
    "print(root_mean_squared_error(teste_y_media, y_namedia_tree))\n",
    "print(\"\\nKNN\")\n",
    "print(root_mean_squared_error(teste_y_media, y_namedia_knn))\n",
    "print(\"\\nGBR\")\n",
    "print(root_mean_squared_error(teste_y_media, y_namedia_gbr))\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(root_mean_squared_error(teste_y_media, y_namedia_lor))\n",
    "print(\"\\nRidge\")\n",
    "print(root_mean_squared_error(teste_y_media, y_namedia_ridge))\n",
    "print(\"\\nBayesian Ridge\")\n",
    "print(root_mean_squared_error(teste_y_media, y_namedia_brr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NaN por Mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "36055.310690629514\n",
      "\n",
      "Decision Tree\n",
      "34013.71426658524\n",
      "\n",
      "KNN\n",
      "53488.18385333421\n",
      "\n",
      "GBR\n",
      "23125.9818814507\n",
      "\n",
      "Logistic Regression\n",
      "51854.51240034369\n",
      "\n",
      "Ridge\n",
      "36042.55239994742\n",
      "\n",
      "Bayesian Ridge\n",
      "40228.513586626104\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression\")\n",
    "print(root_mean_squared_error(teste_y_mediana, y_namediana_rl))\n",
    "print(\"\\nDecision Tree\")\n",
    "print(root_mean_squared_error(teste_y_mediana, y_namediana_tree))\n",
    "print(\"\\nKNN\")\n",
    "print(root_mean_squared_error(teste_y_mediana, y_namediana_knn))\n",
    "print(\"\\nGBR\")\n",
    "print(root_mean_squared_error(teste_y_mediana, y_namediana_gbr))\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(root_mean_squared_error(teste_y_mediana, y_namediana_lor))\n",
    "print(\"\\nRidge\")\n",
    "print(root_mean_squared_error(teste_y_mediana, y_namediana_ridge))\n",
    "print(\"\\nBayesian Ridge\")\n",
    "print(root_mean_squared_error(teste_y_mediana, y_namediana_brr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O modelo para publicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBR com mediana (23125.98188)\n",
    "\n",
    "# Carregamento do dataset\n",
    "teste = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Filtro das colunas utilizadas e imputação dos NaN\n",
    "colunas_quali_teste = teste.columns[teste.dtypes == \"object\"]\n",
    "variaveis_quanti_teste = teste.drop(colunas_quali_teste, axis = 1)\n",
    "variaveis_quanti_teste = variaveis_quanti_teste.drop(\"LotFrontage\", axis = 1)\n",
    "variaveis_quanti_teste = variaveis_quanti_teste.fillna(variaveis_quanti_teste.median())\n",
    "\n",
    "# Gerando as previsões\n",
    "y_gbr = namediana_gbr.predict(variaveis_quanti_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerar arquivo de submissão\n",
    "Pontuação 0.14569 (quanto menor, melhor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste[\"SalePrice\"] = y_gbr\n",
    "resultado = teste[[\"Id\", \"SalePrice\"]]\n",
    "resultado.to_csv(\"resultado.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
